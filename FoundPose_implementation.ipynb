{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMoh0+u4hV9rTbQNLhFmSdW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ggmeiner22/FoundPose/blob/main/FoundPose_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📂 Clone Repository & 🔑 Mount Google Drive  & Install PyTorch3D/dependencies\n",
        "\n",
        "Clone the repository and mount **Google Drive** (requires user interaction).  \n",
        "This will also set up the environment and install the necessary libraries."
      ],
      "metadata": {
        "id": "fTMwM0VF7EsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --quiet install ipython-autotime\n",
        "%load_ext autotime\n",
        "\n",
        "!rm -rf /content/sample_data"
      ],
      "metadata": {
        "id": "saMhMvme7LAl",
        "outputId": "796b308f-2265-4ad0-9348-8ad5e7838e0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.4/1.6 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25htime: 109 ms (started: 2025-10-15 20:16:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set name and email for GitHub Cloning"
      ],
      "metadata": {
        "id": "ffQLREIR7gDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"penguini128\"\n",
        "!git config --global user.email \"tgalletta2022@my.fit.edu\""
      ],
      "metadata": {
        "id": "zxr8G06q7iXh",
        "outputId": "c28d13e5-0cde-47ed-85a8-22269d8aa52d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 217 ms (started: 2025-10-15 20:16:39 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gh_clone(user, repo, token_key=\"GH_TOKEN\"):\n",
        "    from google.colab import userdata\n",
        "    token = userdata.get(token_key)\n",
        "    url = f\"https://{user}:{token}@github.com/{user}/{repo}.git\"\n",
        "    !git clone \"$url\"\n",
        "    !git remote set-url origin $url\n",
        "    del token"
      ],
      "metadata": {
        "id": "4SBfeSVd70IT",
        "outputId": "8c1d2608-4cc3-486a-f367-81cba999a87c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 872 µs (started: 2025-10-15 20:16:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clone the Repository\n",
        "This cell will clone the repository and the helper functions we will need."
      ],
      "metadata": {
        "id": "QuVmCToi74IN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gh_clone(\"ggmeiner22\", \"FoundPose\")\n",
        "\n",
        "# ✅ Verify that the repository was cloned\n",
        "import os\n",
        "repo_name = \"/content/FoundPose\"   # <-- change to your repository folder name\n",
        "if os.path.exists(repo_name):\n",
        "    print(f\"✅ Repository '{repo_name}' successfully cloned!\")\n",
        "else:\n",
        "    print(f\"❌ Repository '{repo_name}' not found. Try cloning manually.\")"
      ],
      "metadata": {
        "id": "NAel_R6S73k0",
        "outputId": "2fff723b-1619-4361-908f-ff524e89b878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FoundPose'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 15 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (15/15), 6.25 MiB | 26.13 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "✅ Repository '/content/FoundPose' successfully cloned!\n",
            "time: 1.75 s (started: 2025-10-15 20:16:40 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "ZtC27Sx68NmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import auth\n",
        "\n",
        "# auth.authenticate_user()\n",
        "\n",
        "local_path = \"\"\n",
        "\n",
        "# Mount google drive if using Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    print('Running on CoLab')\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    local_path = \"/content/\"\n",
        "    os.makedirs(\"/content/matching_results\", exist_ok=True)\n",
        "else:\n",
        "    local_path = \"/teamspace/studios/this_studio/\"\n",
        "    os.makedirs(\"/teamspace/studios/this_studio/matching_results\", exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "os.chdir(local_path)\n",
        "\n",
        "\n",
        "from moviepy.video.io.ImageSequenceClip import ImageSequenceClip\n",
        "\n",
        "os.makedirs(\"/content/matching_results\", exist_ok=True)"
      ],
      "metadata": {
        "id": "V9eCSf0E8Rt-",
        "outputId": "39a43e6f-ecad-4045-c288-af6ca1242d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on CoLab\n",
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 26.5 s (started: 2025-10-15 20:16:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ Install Pytorch3D and other libraries"
      ],
      "metadata": {
        "id": "XHeMyyxa9hDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚡ Install PyTorch3D from Wheel\n",
        "PyTorch3D installation can take longer than 8-10 minutes when installed from source.\n",
        "\n",
        "Here, PyTorch3D is installed from a wheel for a faster setup of about 2 minutes in Colab.\n",
        "\n",
        "If the installer instead tries to build from source, it means the wheel is outdated or missing.\n",
        "In that case, you can create your own wheel directly in Colab, save it to Google Drive (or Dropbox), and reuse it later for faster installation.\n",
        "To create your own PyTorch3D wheel in Colab, follow the instructions in the cell after these installation cells."
      ],
      "metadata": {
        "id": "-Mn9UWub9ie1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set path for libraries\n",
        "import sys\n",
        "sys.path.append('/content/FoundPose')\n",
        "\n",
        "!wget -q -O installation_tools.py \\\n",
        "  https://raw.githubusercontent.com/ribeiro-computer-vision/pytorch3d_rendering/main/installation_tools.py"
      ],
      "metadata": {
        "id": "lUE3Dy3f9mYm",
        "outputId": "0d0029a5-91ab-460d-f94b-83041147e65d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 209 ms (started: 2025-10-15 20:17:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Config ---\n",
        "mount_gdrive = False\n",
        "\n",
        "# --- Imports (module you saved as sse_env.py) ---\n",
        "import importlib, os, sys, shutil, subprocess, urllib.request, pathlib\n",
        "import installation_tools as install_tools\n",
        "importlib.reload(install_tools)\n",
        "\n",
        "# --- Short helpers (no notebook magics) ---\n",
        "def run(cmd, check=True):\n",
        "    print(\"$\", \" \".join(cmd))\n",
        "    try:\n",
        "        subprocess.run(cmd, check=check)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed ({e.returncode}): {' '.join(cmd)}\")\n",
        "        if check:\n",
        "            raise\n",
        "\n",
        "def pip_install(*pkgs, extra=None, check=True):\n",
        "    args = [sys.executable, \"-m\", \"pip\", \"install\"]\n",
        "    if extra:\n",
        "        args += extra\n",
        "    args += list(pkgs)\n",
        "    run(args, check=check)\n",
        "\n",
        "def conda_available():\n",
        "    return shutil.which(\"conda\") is not None\n",
        "\n",
        "def conda_install(*pkgs):\n",
        "    if not conda_available():\n",
        "        print(\"conda not available; skipping conda installs.\")\n",
        "        return\n",
        "    # Use -c conda-forge channel and auto-yes\n",
        "    run([\"conda\", \"install\", \"-y\", \"-c\", \"conda-forge\", *pkgs], check=False)\n",
        "\n",
        "# --- Detect platform ---\n",
        "pm = install_tools.PlatformManager()\n",
        "platform, local_path = pm.platform, pm.local_path\n",
        "print(\"Detected:\", platform, local_path)\n",
        "\n",
        "# --- Optional: Mount GDrive if on Colab ---\n",
        "if mount_gdrive and platform == \"Colab\":\n",
        "    pm.mount_gdrive()\n",
        "\n",
        "# --- Lightning AI specific environment tweaks ---\n",
        "if platform == \"LightningAI\":\n",
        "    # conda piece (if conda exists in the image)\n",
        "    conda_install(\"libstdcxx-ng=13\")\n",
        "    # pip pins / extras\n",
        "    pip_install(\"numpy<2.0\", check=False)\n",
        "    pip_install(\"scikit-image\", \"gradio\", \"moviepy\", \"plotly\", check=False)\n",
        "    # If requirements.txt exists in CWD, install it\n",
        "    if os.path.exists(\"requirements.txt\"):\n",
        "        pip_install(\"-r\", \"requirements.txt\")\n",
        "\n",
        "# --- Install PyTorch3D (handles platform differences & fallbacks) ---\n",
        "installer = install_tools.PyTorch3DInstaller(platform, local_path)\n",
        "installer.install()\n",
        "\n",
        "# --- Extra libraries (quiet-ish) ---\n",
        "# Original line had: trimesh pyrender opencv-python matplotlib pytorch-lightning\n",
        "pip_install(\"trimesh\", \"pyrender\", \"opencv-python\", \"matplotlib\", \"pytorch-lightning\", \"torch\", \"torchvision\", \"timm\", \"scikit-learn\", \"numpy\", \"Pillow\", check=False)\n",
        "\n",
        "# --- Download plot_image_grid.py if missing ---\n",
        "filename = \"plot_image_grid.py\"\n",
        "url = \"https://raw.githubusercontent.com/facebookresearch/pytorch3d/main/docs/tutorials/utils/plot_image_grid.py\"\n",
        "if not os.path.exists(filename):\n",
        "    print(f\"Downloading {filename} ...\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, filename)\n",
        "        print(\"Saved to\", pathlib.Path(filename).resolve())\n",
        "    except Exception as e:\n",
        "        print(\"Download failed:\", e)\n",
        "\n",
        "# --- gdown ---\n",
        "pip_install(\"gdown\", extra=[\"--quiet\"], check=False)\n",
        "print(\"✅ Setup complete.\")"
      ],
      "metadata": {
        "id": "tgtbvsJz-zcV",
        "outputId": "d9f42ff4-a225-4b83-dbee-3998948a211c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Colab.\n",
            "Detected: Colab /content/\n",
            "$ /usr/bin/python3 -m pip install --upgrade pip\n",
            "$ /usr/bin/python3 -m pip install --upgrade pip\n",
            "$ sudo apt-get -qq update\n",
            "$ sudo apt-get install -y freeglut3-dev libglew-dev libsdl2-dev\n",
            "$ /usr/bin/python3 -m pip install PyOpenGL PyOpenGL_accelerate\n",
            "\n",
            "PyTorch3D target wheel tag: py312_cu126_pyt280\n",
            "\n",
            "$ /usr/bin/python3 -m pip install iopath\n",
            "Trying to install PyTorch3D wheel on Colab (Linux).\n",
            "$ /usr/bin/python3 -m pip install https://www.dropbox.com/scl/fi/fqvlnyponcbekjd01omhj/pytorch3d-0.7.8-cp312-cp312-linux_x86_64.whl?rlkey=563mfx35rog42z1c8y7qn31sk&dl=1\n",
            "✅ PyTorch3D successfully installed!\n",
            "$ /usr/bin/python3 -m pip install trimesh pyrender opencv-python matplotlib pytorch-lightning torch torchvision timm scikit-learn numpy Pillow\n",
            "Downloading plot_image_grid.py ...\n",
            "Saved to /content/plot_image_grid.py\n",
            "$ /usr/bin/python3 -m pip install --quiet gdown\n",
            "✅ Setup complete.\n",
            "time: 59.6 s (started: 2025-10-15 20:17:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import cv2\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import trimesh\n",
        "import pyrender\n",
        "import timm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"   # must be set before importing pyrender/pyglet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23jG_omBCyJT",
        "outputId": "22ee15a3-b67c-4b63-bf51-758060515a06"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 922 µs (started: 2025-10-15 20:25:23 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FoundPose (helpers): minimal components reproduction on a synthetic cube.\n",
        "\n",
        "What this script does:\n",
        "1) Offline onboarding:\n",
        "   - Render N RGB-D templates of a unit cube at different orientations (pyrender).\n",
        "   - Extract DINOv2 ViT-L/14 patch descriptors from an intermediate layer (≈ layer 18 analog).\n",
        "   - Compute PCA (to 256D) and per-template Bag-of-Words (k-means vocabulary).\n",
        "   - Store per-patch 3D points (from depth) to enable 2D-3D correspondences later.\n",
        "\n",
        "2) Inference (single query):\n",
        "   - Render a query RGB-D of the same cube at a new pose (unknown to the solver).\n",
        "   - Extract query patch descriptors, build query BoW, retrieve top-k templates by cosine sim.\n",
        "   - For each retrieved template: match query->template patch descriptors (1-NN),\n",
        "     lift template patch centers to 3D, estimate pose with EPnP+RANSAC.\n",
        "   - Take the hypothesis with most inliers (and lowest reprojection RMSE).\n",
        "\n",
        "Notes:\n",
        "- This demo keeps things simple and CPU-friendly.\n",
        "- For real data, replace the synthetic renderer with your image/mask crops.\n"
      ],
      "metadata": {
        "id": "vFgRqWcvFWH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Config (scale these later)\n",
        "# ---------------------------\n",
        "IMG_SIZE = 518\n",
        "PATCH = 14                  # DINOv2 ViT-L/14 patch size\n",
        "GRID = IMG_SIZE // PATCH    # 37\n",
        "NUM_TEMPLATES = 800          # (paper ~800; keep small for demo)\n",
        "VOCAB_K = 512               # BoW vocab size (paper ~2048)\n",
        "TOP_K_RETRIEVE = 12\n",
        "PCA_DIM = 256               # (paper uses 256)\n",
        "RANSAC_ITERS = 2000\n",
        "RANSAC_REPROJ_THRESH = 8.0  # px\n",
        "FOCAL = 600.0               # simple intrinsics (fx=fy)\n",
        "CX = IMG_SIZE/2.0\n",
        "CY = IMG_SIZE/2.0\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TAjRbYcFa40",
        "outputId": "7c2fdf6f-d36b-4771-b556-1949cd6f2340"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.36 ms (started: 2025-10-15 20:39:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DINOv2 feature extractor\n",
        "\n",
        "We use timm to load a DINOv2 ViT-L/14 model and grab a mid-level token map akin to\n",
        "\"intermediate layer features\" (the paper reports best at ViT-L layer ~18). Exact layer\n",
        "indices differ across repos; as a practical demo we:\n",
        "- take the last block token map and/or a mid block by hook (works similarly in practice),\n",
        "- reshape (B, tokens, C) to (B, H, W, C) where H=W=IMG_SIZE/PATCH."
      ],
      "metadata": {
        "id": "qLsKjqT-GGTj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DinoV2Grid:\n",
        "    def __init__(self, model_name=\"vit_large_patch14_dinov2.lvd142m\", target_block=-6):\n",
        "        \"\"\"\n",
        "        model_name: a timm DINOv2 ViT-L/14 variant.\n",
        "        target_block: which transformer block's output tokens to use.\n",
        "                      -6 means \"sixth from last\" (mid-ish); adjust as desired.\n",
        "        \"\"\"\n",
        "        self.model = timm.create_model(model_name, pretrained=True)\n",
        "        self.model.eval().to(DEVICE)\n",
        "        self.target_block = target_block\n",
        "        self._tokens = None\n",
        "\n",
        "        # register hook on blocks[target_block]\n",
        "        blocks = self.model.blocks\n",
        "        idx = target_block if target_block >= 0 else len(blocks) + target_block\n",
        "        def hook_fn(module, inp, out):\n",
        "            # out shape: (B, tokens+1, C); token 0 is cls token\n",
        "            self._tokens = out.detach()\n",
        "        blocks[idx].register_forward_hook(hook_fn)\n",
        "\n",
        "        # patch embed stride should be 14 for ViT-L/14\n",
        "        # we’ll resize input to IMG_SIZE so tokens grid = 30x30\n",
        "\n",
        "        # Normalization (timm default for this model)\n",
        "        data_cfg = timm.data.resolve_model_data_config(self.model)\n",
        "        self.transforms = timm.data.create_transform(**data_cfg, is_training=False)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def extract_grid(self, img_pil: Image.Image) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Returns (H=GRID, W=GRID, C) patch descriptors as float32 numpy array.\n",
        "        \"\"\"\n",
        "        img_res = img_pil.resize((IMG_SIZE, IMG_SIZE), Image.BICUBIC)\n",
        "        x = self.transforms(img_res).unsqueeze(0).to(DEVICE)  # (1,3,H,W) normalized\n",
        "        _ = self.model(x)  # triggers hook\n",
        "        tokens = self._tokens  # (1, 1+HW, C)\n",
        "        assert tokens is not None, \"Hook did not capture tokens\"\n",
        "\n",
        "        tokens = tokens[:, 1:, :]  # drop cls\n",
        "        B, HW, C = tokens.shape\n",
        "        assert B == 1 and HW == GRID*GRID, f\"Unexpected tokens: {tokens.shape}\"\n",
        "\n",
        "        H = W = int(math.sqrt(HW))\n",
        "        grid = tokens.view(B, H, W, C).cpu().float().numpy()[0]\n",
        "        #grid = tokens.view(1, GRID, GRID, C).cpu().float().numpy()[0]  # (H,W,C)\n",
        "        return grid  # float32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ZbJdcIF8bf",
        "outputId": "85abc2d0-ab16-47df-eeac-3af126b22f11"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.95 ms (started: 2025-10-15 20:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rendering utilities"
      ],
      "metadata": {
        "id": "vqWxdhJmGgcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_scene():\n",
        "    # Unit cube centered at origin\n",
        "    mesh = trimesh.creation.box(extents=(1,1,1))\n",
        "    mesh.visual.vertex_colors = [180, 200, 240, 255]\n",
        "    tm = pyrender.Mesh.from_trimesh(mesh, smooth=False)\n",
        "\n",
        "    scene = pyrender.Scene(bg_color=[0,0,0,0])\n",
        "    mnode = scene.add(tm)\n",
        "\n",
        "    # Simple directional light\n",
        "    light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
        "    scene.add(light, pose=np.eye(4))\n",
        "\n",
        "    return scene, mnode\n",
        "\n",
        "def camera_pose_from_euler(rx, ry, rz, dist=2.5):\n",
        "    # Look-at from spherical angles around origin; put camera on a sphere\n",
        "    Rx = trimesh.transformations.rotation_matrix(np.deg2rad(rx), [1,0,0])\n",
        "    Ry = trimesh.transformations.rotation_matrix(np.deg2rad(ry), [0,1,0])\n",
        "    Rz = trimesh.transformations.rotation_matrix(np.deg2rad(rz), [0,0,1])\n",
        "    R = trimesh.transformations.concatenate_matrices(Rz, Ry, Rx)\n",
        "    t = np.array([0, 0, dist, 1.0])\n",
        "    T = R.copy()\n",
        "    T[:,3] = t\n",
        "    return T\n",
        "\n",
        "def render_rgbd(rx, ry, rz, dist=2.5, img_size=IMG_SIZE):\n",
        "    scene, mnode = make_scene()\n",
        "\n",
        "    # Pinhole intrinsics\n",
        "    camera = pyrender.IntrinsicsCamera(fx=FOCAL, fy=FOCAL, cx=CX, cy=CY)\n",
        "    cam_node = scene.add(camera, pose=np.eye(4))\n",
        "\n",
        "    # Pose cube (we'll leave cube at origin) and place camera\n",
        "    cam_pose = camera_pose_from_euler(rx, ry, rz, dist=dist)\n",
        "    scene.set_pose(cam_node, pose=cam_pose)\n",
        "\n",
        "    r = pyrender.OffscreenRenderer(viewport_width=img_size, viewport_height=img_size)\n",
        "    color, depth = r.render(scene, flags=pyrender.RenderFlags.RGBA)\n",
        "    r.delete()\n",
        "    # convert RGBA to RGB (black background)\n",
        "    rgb = color[..., :3]\n",
        "    return rgb, depth, cam_pose\n",
        "\n",
        "# 3D from depth & intrinsics\n",
        "def backproject(u, v, depth):\n",
        "    z = depth[v, u]\n",
        "    if z == 0:\n",
        "        return None\n",
        "    x = (u - CX) * z / FOCAL\n",
        "    y = (v - CY) * z / FOCAL\n",
        "    return np.array([x, y, z], dtype=np.float32)"
      ],
      "metadata": {
        "id": "ogra5AqeGguT",
        "outputId": "12ae4ccb-7565-41cd-9faa-d62b3d216410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.2 ms (started: 2025-10-15 20:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patch extraction helpers"
      ],
      "metadata": {
        "id": "h8-6DJtGGpwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_centers(img_size=IMG_SIZE, patch=PATCH):\n",
        "    # returns list of (u,v) pixel centers for each 14x14 patch center\n",
        "    coords = []\n",
        "    offset = patch / 2.0\n",
        "    for gy in range(GRID):\n",
        "        for gx in range(GRID):\n",
        "            u = int(gx*patch + offset)\n",
        "            v = int(gy*patch + offset)\n",
        "            # clamp inside image\n",
        "            u = min(max(u, 0), img_size-1)\n",
        "            v = min(max(v, 0), img_size-1)\n",
        "            coords.append((u, v))\n",
        "    return coords  # length GRID*GRID"
      ],
      "metadata": {
        "id": "RWNpj6BxGp_w",
        "outputId": "e36ce1cf-62de-479e-9923-9dd3681f346d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.02 ms (started: 2025-10-15 20:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Onboarding (templates)"
      ],
      "metadata": {
        "id": "-AWLUMlDGv4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_orientations(n=NUM_TEMPLATES, seed=0):\n",
        "    random.seed(seed)\n",
        "    oris = []\n",
        "    for _ in range(n):\n",
        "        rx = random.uniform(-60, 60)\n",
        "        ry = random.uniform(-60, 60)\n",
        "        rz = random.uniform(-180, 180)\n",
        "        oris.append((rx, ry, rz))\n",
        "    return oris\n",
        "\n",
        "def build_templates(dino: DinoV2Grid):\n",
        "    coords = grid_centers()\n",
        "    T_desc = []      # list of (H,W,C) descriptors (before PCA)\n",
        "    T_3d = []        # list of per-patch 3D points IN MODEL SPACE (H*W, 3)\n",
        "    orientations = sample_orientations()\n",
        "\n",
        "    print(f\"[Onboarding] Rendering {len(orientations)} templates...\")\n",
        "    all_desc = []\n",
        "    for (rx, ry, rz) in orientations:\n",
        "        rgb, depth, cam_pose = render_rgbd(rx, ry, rz)\n",
        "        img = Image.fromarray(rgb)\n",
        "        grid = dino.extract_grid(img)         # (H,W,C)\n",
        "        T_desc.append(grid)\n",
        "\n",
        "        # Back-project to CAMERA frame, then transform to WORLD/MODEL frame\n",
        "        # cam_pose is camera->world; so X_world = cam_pose @ X_cam_h\n",
        "        xyzs = []\n",
        "        for (u, v) in coords:\n",
        "            p3 = backproject(u, v, depth)  # camera frame\n",
        "            if p3 is None:\n",
        "                xyzs.append([np.nan, np.nan, np.nan])\n",
        "                continue\n",
        "            X_cam_h = np.array([p3[0], p3[1], p3[2], 1.0], dtype=np.float32)\n",
        "            X_w_h = cam_pose.astype(np.float32) @ X_cam_h\n",
        "            xyzs.append(X_w_h[:3])  # world/model frame (cube at origin)\n",
        "        T_3d.append(np.stack(xyzs, axis=0))   # (H*W, 3)\n",
        "\n",
        "        all_desc.append(grid.reshape(-1, grid.shape[-1]))\n",
        "\n",
        "    all_desc = np.concatenate(all_desc, axis=0)  # (N*H*W, C)\n",
        "    print(f\"[Onboarding] All descriptor stack: {all_desc.shape}\")\n",
        "\n",
        "    # PCA to 256D\n",
        "    print(\"[Onboarding] PCA(256)...\")\n",
        "    pca = PCA(n_components=PCA_DIM, whiten=False, random_state=0)\n",
        "    pca.fit(all_desc)\n",
        "    T_desc_pca = [pca.transform(t.reshape(-1, t.shape[-1])).astype(np.float32) for t in T_desc]\n",
        "\n",
        "    # k-means vocab (BoW)\n",
        "    print(f\"[Onboarding] MiniBatchKMeans(K={VOCAB_K})...\")\n",
        "    kmeans = MiniBatchKMeans(n_clusters=VOCAB_K, batch_size=8192, random_state=0, n_init=5)\n",
        "    kmeans.fit(np.concatenate(T_desc_pca, axis=0))\n",
        "    vocab = kmeans.cluster_centers_.astype(np.float32)\n",
        "\n",
        "    # soft-assignment BoW\n",
        "    def bow_from_desc(desc_pca):\n",
        "        d2 = cosine_similarity(desc_pca, vocab)  # (M,K) cosine sim\n",
        "        top3 = np.argpartition(-d2, 3, axis=1)[:, :3]\n",
        "        bow = np.zeros((VOCAB_K,), dtype=np.float32)\n",
        "        for i, idxs in enumerate(top3):\n",
        "            sims = d2[i, idxs]\n",
        "            sims = np.clip(sims, 0, None)\n",
        "            if sims.sum() > 0:\n",
        "                sims = sims / (sims.sum() + 1e-8)\n",
        "            for j, w in zip(idxs, sims):\n",
        "                bow[j] += w\n",
        "        bow = bow / (bow.sum() + 1e-8)\n",
        "        return bow\n",
        "\n",
        "    print(\"[Onboarding] Building per-template BoWs...\")\n",
        "    T_bow = [bow_from_desc(d) for d in T_desc_pca]\n",
        "\n",
        "    return {\n",
        "        \"desc_pca\": T_desc_pca,           # list of (M, D)\n",
        "        \"xyz_model\": T_3d,                # list of (M, 3) in model/world frame\n",
        "        \"bow\": np.stack(T_bow, 0),        # (T, K)\n",
        "        \"pca\": pca,\n",
        "        \"vocab\": vocab,\n",
        "        \"orientations\": orientations\n",
        "    }"
      ],
      "metadata": {
        "id": "keY_JOENGwIV",
        "outputId": "f0e0630f-d179-4156-8f0d-dea3a28e5975",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.6 ms (started: 2025-10-15 20:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on a query"
      ],
      "metadata": {
        "id": "OVLJEtZUG41o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def render_query():\n",
        "    # new pose not in the onboarding set\n",
        "    rx, ry, rz = 35.0, -30.0, 45.0\n",
        "    rgb, depth, cam_pose = render_rgbd(rx, ry, rz)\n",
        "    return Image.fromarray(rgb), depth\n",
        "\n",
        "def extract_query(dino: DinoV2Grid, pca, vocab):\n",
        "    img_pil, depth = render_query()\n",
        "    grid = dino.extract_grid(img_pil)                 # (H,W,C)\n",
        "    desc = grid.reshape(-1, grid.shape[-1])\n",
        "    desc_pca = pca.transform(desc).astype(np.float32) # (M, D)\n",
        "    # query BoW (same soft assignment)\n",
        "    d2 = cosine_similarity(desc_pca, vocab)           # (M,K)\n",
        "    top3 = np.argpartition(-d2, 3, axis=1)[:, :3]\n",
        "    bow = np.zeros((VOCAB_K,), dtype=np.float32)\n",
        "    for i, idxs in enumerate(top3):\n",
        "        sims = d2[i, idxs]\n",
        "        sims = np.clip(sims, 0, None)\n",
        "        if sims.sum() > 0:\n",
        "            sims = sims / (sims.sum() + 1e-8)\n",
        "        for j, w in zip(idxs, sims):\n",
        "            bow[j] += w\n",
        "    bow = bow / (bow.sum() + 1e-8)\n",
        "    return img_pil, depth, desc_pca, bow\n",
        "\n",
        "def retrieve_templates(query_bow, T_bow):\n",
        "    sims = cosine_similarity(query_bow[None, :], T_bow)[0]  # (T,)\n",
        "    idxs = np.argsort(-sims)[:TOP_K_RETRIEVE]\n",
        "    return idxs, sims[idxs]\n",
        "\n",
        "def correspondences(query_desc, template_desc, template_xyz, coords_uv, ratio=0.7, max_pairs=800):\n",
        "    # L2-normalize\n",
        "    q = query_desc / (np.linalg.norm(query_desc, axis=1, keepdims=True) + 1e-8)\n",
        "    t = template_desc / (np.linalg.norm(template_desc, axis=1, keepdims=True) + 1e-8)\n",
        "\n",
        "    # cosine sims\n",
        "    sim_qt = q @ t.T                           # (Mq, Mt)\n",
        "    # top-2 per query for ratio test\n",
        "    top2 = np.sort(sim_qt, axis=1)[:, -2:]\n",
        "    keep = top2[:,1] >= ratio * (top2[:,0] + 1e-8)\n",
        "\n",
        "    # greedy 1-NN (no mutual check)\n",
        "    nn = np.argmax(sim_qt, axis=1)             # (Mq,)\n",
        "\n",
        "    # build pairs\n",
        "    pairs = []\n",
        "    for qi, tj in enumerate(nn):\n",
        "        if not keep[qi]:\n",
        "            continue\n",
        "        p3 = template_xyz[tj]\n",
        "        if np.any(np.isnan(p3)):\n",
        "            continue\n",
        "        sim = sim_qt[qi, tj]\n",
        "        u, v = coords_uv[qi]\n",
        "        pairs.append((sim, u, v, p3[0], p3[1], p3[2]))\n",
        "\n",
        "    if not pairs:\n",
        "        return np.empty((0,2), np.float32), np.empty((0,3), np.float32)\n",
        "\n",
        "    # keep the best-N sims\n",
        "    pairs.sort(key=lambda x: x[0], reverse=True)\n",
        "    pairs = pairs[:max_pairs]\n",
        "\n",
        "    uv  = np.array([[p[1], p[2]] for p in pairs], dtype=np.float32)\n",
        "    xyz = np.array([[p[3], p[4], p[5]] for p in pairs], dtype=np.float32)\n",
        "    return uv, xyz\n",
        "\n",
        "\n",
        "def solve_pnp_ransac(uv, xyz):\n",
        "    if len(uv) < 6:\n",
        "        return None\n",
        "    K = np.array([[FOCAL, 0, CX],\n",
        "                  [0, FOCAL, CY],\n",
        "                  [0, 0, 1]], dtype=np.float64)\n",
        "    dist = np.zeros(5)\n",
        "    ok, rvec, tvec, inliers = cv2.solvePnPRansac(\n",
        "        xyz.astype(np.float64),\n",
        "        uv.astype(np.float64),\n",
        "        K, dist,\n",
        "        iterationsCount=RANSAC_ITERS,\n",
        "        reprojectionError=RANSAC_REPROJ_THRESH,\n",
        "        flags=cv2.SOLVEPNP_EPNP\n",
        "    )\n",
        "    if not ok:\n",
        "        return None\n",
        "    # compute RMSE reprojection on inliers\n",
        "    proj, _ = cv2.projectPoints(xyz[inliers[:,0]], rvec, tvec, K, dist)\n",
        "    err = np.linalg.norm(proj.squeeze() - uv[inliers[:,0]], axis=1)\n",
        "    rmse = float(np.sqrt((err**2).mean()))\n",
        "    return {\n",
        "        \"rvec\": rvec, \"tvec\": tvec,\n",
        "        \"inliers\": inliers, \"rmse\": rmse,\n",
        "        \"num_inliers\": len(inliers)\n",
        "    }"
      ],
      "metadata": {
        "id": "bzxhr1uUG7G-",
        "outputId": "f32649ba-2c8c-4fe7-9547-d25a8d76347d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 23.5 ms (started: 2025-10-15 20:18:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FoundPose (Demo)"
      ],
      "metadata": {
        "id": "Q16gcXICHE8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initilize the model"
      ],
      "metadata": {
        "id": "Wx3SPZTEIe9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dino = DinoV2Grid(model_name=\"vit_large_patch14_dinov2.lvd142m\", target_block=-6)"
      ],
      "metadata": {
        "id": "zsPNfFFBHEiP",
        "outputId": "77481296-cee0-422d-8a49-3f45ccad538a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.29 s (started: 2025-10-15 20:39:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Onboard templates (can take time; cache if needed)"
      ],
      "metadata": {
        "id": "1njnDReze8Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "templates = build_templates(dino)   # builds PCA, vocab, desc_pca, xyz_model, bow\n",
        "len(templates[\"desc_pca\"]), templates[\"bow\"].shape"
      ],
      "metadata": {
        "id": "qMbH8ZHTe8ug",
        "outputId": "43e4b2c3-a4dd-4c33-9ace-2ba099f90b4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Onboarding] Rendering 60 templates...\n",
            "[Onboarding] All descriptor stack: (82140, 1024)\n",
            "[Onboarding] PCA(256)...\n",
            "[Onboarding] MiniBatchKMeans(K=512)...\n",
            "[Onboarding] Building per-template BoWs...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, (60, 512))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2min 18s (started: 2025-10-15 20:25:29 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Render a query, extract descriptors + BoW, retrieve candidates"
      ],
      "metadata": {
        "id": "cO9THiptjyQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[Query] Rendering + extracting...\")\n",
        "q_img, q_depth, q_desc_pca, q_bow = extract_query(dino, templates[\"pca\"], templates[\"vocab\"])\n",
        "\n",
        "top_idxs, top_sims = retrieve_templates(q_bow, templates[\"bow\"])\n",
        "print(\"[Retrieve] Top templates:\", list(zip(top_idxs.tolist(), np.round(top_sims, 3).tolist())))"
      ],
      "metadata": {
        "id": "LUphcRA6jza8",
        "outputId": "ca7b4f9f-298b-40fe-ef34-a2fbdcec7970",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Query] Rendering + extracting...\n",
            "[Retrieve] Top templates: [(20, 0.7799999713897705), (2, 0.7630000114440918), (45, 0.753000020980835), (28, 0.671999990940094), (48, 0.6620000004768372), (23, 0.6610000133514404), (11, 0.5889999866485596), (7, 0.5569999814033508), (13, 0.5569999814033508), (14, 0.5569999814033508), (9, 0.5569999814033508), (10, 0.5569999814033508)]\n",
            "time: 888 ms (started: 2025-10-15 20:28:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build query 2D coordinates"
      ],
      "metadata": {
        "id": "tsxcPmC9j3fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coords_uv = np.array(grid_centers(), dtype=np.float32)  # fixed GRID version\n",
        "coords_uv.shape"
      ],
      "metadata": {
        "id": "PZtY8Uftj7GY",
        "outputId": "b5addba3-114f-4509-c5cc-e213df861c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1369, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.4 ms (started: 2025-10-15 20:29:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try PnP for each retrieved template"
      ],
      "metadata": {
        "id": "OJ7lNRlqkDIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = None\n",
        "for tidx in top_idxs:\n",
        "    uv, xyz = correspondences(\n",
        "        q_desc_pca,\n",
        "        templates[\"desc_pca\"][tidx],\n",
        "        templates[\"xyz_model\"][tidx],\n",
        "        coords_uv\n",
        "    )\n",
        "    print(f\"[DBG] tidx={tidx}: matches={len(uv)}\")\n",
        "    res = solve_pnp_ransac(uv, xyz)\n",
        "    if res is None:\n",
        "        continue\n",
        "    cand = (res[\"num_inliers\"], -res[\"rmse\"], tidx, res)\n",
        "    if (best is None) or (cand > best):\n",
        "        best = cand"
      ],
      "metadata": {
        "id": "Z92lnN2IkE36",
        "outputId": "13cabffd-f14e-46e8-c3b8-93a5591979ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DBG] tidx=20: matches=1\n",
            "[DBG] tidx=2: matches=2\n",
            "[DBG] tidx=45: matches=1\n",
            "[DBG] tidx=28: matches=3\n",
            "[DBG] tidx=48: matches=2\n",
            "[DBG] tidx=23: matches=1\n",
            "[DBG] tidx=11: matches=1\n",
            "[DBG] tidx=7: matches=0\n",
            "[DBG] tidx=13: matches=0\n",
            "[DBG] tidx=14: matches=0\n",
            "[DBG] tidx=9: matches=0\n",
            "[DBG] tidx=10: matches=0\n",
            "time: 445 ms (started: 2025-10-15 20:38:13 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle “no solution” early"
      ],
      "metadata": {
        "id": "KwvYN6TRmE6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if best is None:\n",
        "    raise RuntimeError(\"No valid PnP solution — loosen matcher or RANSAC and rerun Cell 5.\")"
      ],
      "metadata": {
        "id": "_o1H6heRmFLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report final pose metrics"
      ],
      "metadata": {
        "id": "6hnENt6fmJW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_inl, neg_rmse, tidx, res = best\n",
        "print(f\"[Pose] Best from template {tidx}: inliers={num_inl}, rmse={-neg_rmse:.3f}px\")\n",
        "res.keys()  # rvec, tvec, inliers, rmse, num_inliers"
      ],
      "metadata": {
        "id": "Lsu1Er3DmKl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize reprojection overlay"
      ],
      "metadata": {
        "id": "o7T-oesgmNNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = np.array([[FOCAL, 0, CX],\n",
        "              [0, FOCAL, CY],\n",
        "              [0, 0, 1]], dtype=np.float64)\n",
        "dist = np.zeros(5)\n",
        "\n",
        "proj, _ = cv2.projectPoints(templates[\"xyz_model\"][tidx], res[\"rvec\"], res[\"tvec\"], K, dist)\n",
        "reproj = proj.squeeze().astype(np.float32)\n",
        "\n",
        "fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
        "ax.imshow(q_img)\n",
        "ax.scatter(reproj[:,0], reproj[:,1], s=5, alpha=0.3)\n",
        "ax.set_title(f\"Best hypothesis (template {tidx})\\nInliers={num_inl}, RMSE={-neg_rmse:.2f}px\")\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "955N-L6vmPQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}